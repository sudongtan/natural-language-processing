{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import sys\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tarfile\n",
    "import urllib\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import sys\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_root = 'data/'\n",
    "try:\n",
    "    os.mkdir(data_root)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root,'train_x_bw.pkl'), 'rb') as f:\n",
    "    train_x_bw = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(data_root,'train_y_bw.pkl'), 'rb') as f:\n",
    "    train_y_bw = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(data_root,'validation_x_bw.pkl'), 'rb') as f:\n",
    "    validation_x_bw = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(data_root,'validation_y_bw.pkl'), 'rb') as f:\n",
    "    validation_y_bw = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_root,'test_x_bw.pkl'), 'rb') as f:\n",
    "    test_x_bw = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(data_root,'test_y_bw.pkl'), 'rb') as f:\n",
    "    test_y_bw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "print len(train_x_bw)\n",
    "print len(validation_x_bw)\n",
    "print len(test_x_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "model_bw = CountVectorizer(analyzer='word',\n",
    "                            tokenizer=None,\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=5000)\n",
    "model_bw = model_bw.fit(train_x_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_root = 'model/'\n",
    "try:\n",
    "    os.mkdir(data_root)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "with open(os.path.join(model_root,'model_bw.pkl'), 'wb') as f:\n",
    "        pickle.dump(model_bw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_x_bw_clf = model_bw.transform(train_x_bw)\n",
    "train_x_bw_clf = train_x_bw_clf.toarray()\n",
    "\n",
    "validation_x_bw_clf = model_bw.transform(validation_x_bw)\n",
    "validation_x_bw_clf = validation_x_bw_clf.toarray()\n",
    "\n",
    "test_x_bw_clf = model_bw.transform(test_x_bw)\n",
    "test_x_bw_clf = test_x_bw_clf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n",
      "(12500, 5000)\n",
      "(12500, 5000)\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "print train_x_bw_clf.shape\n",
    "print validation_x_bw_clf.shape\n",
    "print test_x_bw_clf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print train_x_bw_clf[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rd_clf = RandomForestClassifier(n_estimators = 100, random_state=3)\n",
    "rd_clf = rd_clf.fit(train_x_bw_clf, train_y_bw)\n",
    "accuracy_validation = rd_clf.score(validation_x_bw_clf, validation_y_bw)\n",
    "print accuracy_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf = lr_clf.fit(train_x_bw_clf, train_y_bw)\n",
    "accuracy_validation = lr_clf.score(validation_x_bw_clf, validation_y_bw)\n",
    "print accuracy_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf = svm_clf.fit(train_x_bw_clf, train_y_bw)\n",
    "accuracy_validation = svm_clf.score(validation_x_bw_clf, validation_y_bw)\n",
    "print accuracy_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "random forest:  0.84496\n",
      "logistic regression:  0.85096\n",
      "svm:  0.82536\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "        \n",
    "print \"Accuracy\"\n",
    "print \"random forest: \", rd_clf.score(test_x_bw_clf, test_y_bw)\n",
    "print \"logistic regression: \", lr_clf.score(test_x_bw_clf, test_y_bw)\n",
    "print \"svm: \", svm_clf.score(test_x_bw_clf, test_y_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
