{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "#import urllib2\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import os\n",
    "#import cv2\n",
    "import h5py\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import random as rand\n",
    "from operator import add\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import urllib\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "#import cPickle as pickle\n",
    "import scipy.io as sio\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import sys\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import re\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#import nltk.data\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and save GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_GloVe():\n",
    "    print(\"Loading Glove Model\")\n",
    "    with open(\"data/glove.42B.300d.txt\", \"r\") as f: \n",
    "        \n",
    "        embeddings = np.zeros((1917494,300), dtype=np.float32)\n",
    "        words = {} # np.empty((1917494, 1)) \n",
    "        idx = 0\n",
    "        \n",
    "        for line in tqdm(f, total=1917494):\n",
    "            splitLine = line.split()\n",
    "            word = splitLine[0]\n",
    "            embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "            \n",
    "            embeddings[idx] = embedding\n",
    "            words[word] = idx\n",
    "            \n",
    "            idx += 1\n",
    "\n",
    "    return words, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_GloVe():\n",
    "    print(\"Loading Glove Model\")\n",
    "    with open(\"data/glove.840B.300d.txt\", \"r\") as f: \n",
    "        \n",
    "        embeddings = np.zeros((2196017, 300), dtype=np.float32)\n",
    "        words = {} # np.empty((1917494, 1)) \n",
    "        idx = 0\n",
    "        \n",
    "        for line in tqdm(f, total=2196017):\n",
    "            \n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word = ''.join(values[:-300])\n",
    "            embedding = np.array(values[-300:], dtype='float32')\n",
    "            embeddings[idx] = embedding\n",
    "            words[word] = idx\n",
    "            \n",
    "            idx += 1\n",
    "\n",
    "    return words, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899c67338853456292c9f6cdd27789d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove = load_GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/glove\", 'wb') as f:\n",
    "    pickle.dump(glove, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load and save word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "def load_w2v():\n",
    "    _fname = \"data/GoogleNews-vectors-negative300.bin\"\n",
    "    w2vModel = gensim.models.Word2Vec.load_word2vec_format(_fname, binary=True)\n",
    "    return w2vModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vModel = load_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "w2v_vectors = normalize(w2vModel.wv.syn0)\n",
    "w2v_words = w2vModel.wv.index2word\n",
    "w2v = {}\n",
    "for idx, word in enumerate(w2v_words):\n",
    "    w2v[word] = w2v_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/w2v\", 'wb') as f:\n",
    "    pickle.dump(w2v, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_q1_dirty_aug.npy\t\t    sample_submission.csv\r\n",
      "cv_q1.npy\t\t\t    test.csv\r\n",
      "cv_q2_dirty_aug.npy\t\t    test_pred.npy\r\n",
      "cv_q2.npy\t\t\t    test_q1_dirty.npy\r\n",
      "cv_y_dirty_aug.npy\t\t    test_q1.npy\r\n",
      "cv_y.npy\t\t\t    test_q2_dirty.npy\r\n",
      "features\t\t\t    test_q2.npy\r\n",
      "glove\t\t\t\t    train.csv\r\n",
      "glove.42B.300d.txt\t\t    train_q1_dirty_aug.npy\r\n",
      "glove.840B.300d.txt\t\t    train_q1.npy\r\n",
      "GoogleNews-vectors-negative300.bin  train_q2_dirty_aug.npy\r\n",
      "hyperopt-trials.pkl\t\t    train_q2.npy\r\n",
      "hyperopt-trials.pkl.bkp\t\t    train_y_dirty_aug.npy\r\n",
      "hyperopt-trials.pkl.no-idea\t    train_y.npy\r\n",
      "hyperopt-trials.pkl.no-magic\t    w2v\r\n",
      "quora_duplicate_questions.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'data/glove.820B.300d.txt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls 'data/glove.820B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_q1_dirty_aug.npy\t\t    sample_submission.csv\r\n",
      "cv_q1.npy\t\t\t    test.csv\r\n",
      "cv_q2_dirty_aug.npy\t\t    test_pred.npy\r\n",
      "cv_q2.npy\t\t\t    test_q1_dirty.npy\r\n",
      "cv_y_dirty_aug.npy\t\t    test_q1.npy\r\n",
      "cv_y.npy\t\t\t    test_q2_dirty.npy\r\n",
      "features\t\t\t    test_q2.npy\r\n",
      "glove\t\t\t\t    train.csv\r\n",
      "glove.42B.300d.txt\t\t    train_q1_dirty_aug.npy\r\n",
      "glove.840B.300d.txt\t\t    train_q1.npy\r\n",
      "GoogleNews-vectors-negative300.bin  train_q2_dirty_aug.npy\r\n",
      "hyperopt-trials.pkl\t\t    train_q2.npy\r\n",
      "hyperopt-trials.pkl.bkp\t\t    train_y_dirty_aug.npy\r\n",
      "hyperopt-trials.pkl.no-idea\t    train_y.npy\r\n",
      "hyperopt-trials.pkl.no-magic\t    w2v\r\n",
      "quora_duplicate_questions.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
